{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoqLpvBxGl4xWT71vfehxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yisi22/Real-Estate-Investment/blob/main/Data_Center.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import datetime as dt\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "import random\n",
        "yf.pdr_override()"
      ],
      "metadata": {
        "id": "SLJj-jBuXixC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LQFO7UWmTdd9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn import cluster, covariance, manifold\n",
        "from sklearn.metrics import adjusted_mutual_info_score\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering,AffinityPropagation, DBSCAN\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
        "from scipy.spatial.distance import pdist\n",
        "from sklearn.metrics import adjusted_mutual_info_score\n",
        "from sklearn import cluster, covariance, manifold\n",
        "import matplotlib.ticker as ticker\n",
        "from itertools import cycle\n",
        "from sklearn import metrics\n",
        "from statsmodels.tsa.stattools import coint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = ['EQIX', 'DLR', 'DBRG', 'AJBU.SI', 'AMT','IRM','BX','KKR','COR','GDS','0788.HK', 'NXT.AX']\n",
        "data = yf.download(ticker, start = '2010-1-1')\n",
        "data_ticker = data['Adj Close']"
      ],
      "metadata": {
        "id": "Lsqmpn0EW1j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ticker"
      ],
      "metadata": {
        "id": "A0XH7coGby3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing value\n",
        "def check_missing_value (data):\n",
        "    missing_values = data.isnull().mean().sort_values(ascending = False)\n",
        "    missing_value_frame = missing_values.to_frame().head(20).style.format('{:,.3%}'.format)\n",
        "    drop_list = sorted(list(missing_values[missing_values > 0.3].index))\n",
        "    wrangled_data = data.drop(columns = drop_list, axis =1)\n",
        "    wrangled_data = wrangled_data.ffill()\n",
        "    wrangled_data = wrangled_data.dropna(axis =0)\n",
        "    return missing_value_frame, wrangled_data"
      ],
      "metadata": {
        "id": "4LOon-GhXci8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the wrangled data\n",
        "missing_value_frame, wrangled_data = check_missing_value(data_ticker)"
      ],
      "metadata": {
        "id": "JT08duKOXwwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering using AGNES"
      ],
      "metadata": {
        "id": "uvkUBg36CrCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use AGNES to Cluster\n",
        "def wrangle_data(data):\n",
        "    missing_fractions = data.isnull().mean().sort_values(ascending = False)\n",
        "    drop_list = sorted(list(missing_fractions[missing_fractions > 0.5].index))\n",
        "    data = data.drop(labels = drop_list, axis =1)\n",
        "    data = data.ffill()\n",
        "    returns = data.pct_change().mean()*252\n",
        "    returns = pd.DataFrame(returns, columns = pd.Index(['Returns']))\n",
        "    returns['Volatility'] = data.pct_change().std() * np.sqrt(252)\n",
        "    data_test = np.asarray([np.asarray(returns['Returns']), np.asarray(returns['Volatility'])]).T\n",
        "    scaler = StandardScaler().fit(data_test)\n",
        "    rescaledDataset = pd.DataFrame(scaler.fit_transform(data_test), columns = returns.columns, index = returns.index)\n",
        "    return rescaledDataset\n",
        "def linkage_dendrogram(X, distance):\n",
        "    Z = linkage(X, method = 'ward')\n",
        "    plt.figure(figsize = [18,10])\n",
        "    plt.title('Stock Dendograms')\n",
        "    dendrogram(Z, labels = X.index)\n",
        "    plt.show()\n",
        "    distance_threshold = distance\n",
        "    clusters = fcluster(Z, distance_threshold, criterion = 'distance')\n",
        "    chosen_clusters = pd.DataFrame(data = clusters, columns = ['cluster'])\n",
        "    return chosen_clusters\n",
        "def clustering(X, nclust):\n",
        "    hc = AgglomerativeClustering(n_clusters = nclust, affinity = 'euclidean', linkage = 'ward')\n",
        "    clust_labels = hc.fit_predict(X)\n",
        "    fig = plt.figure(figsize = (16,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    scatter = ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=clust_labels, cmap = 'rainbow')\n",
        "    ax.set_title('Hierachial')\n",
        "    ax.set_xlabel('Average Return')\n",
        "    ax.set_ylabel('Volitility')\n",
        "    plt.colorbar(scatter)\n",
        "    return hc, clust_labels"
      ],
      "metadata": {
        "id": "31UmKc_5ZDCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledDataset = wrangle_data(data_ticker)"
      ],
      "metadata": {
        "id": "OJPrsFAlEBNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledDataset"
      ],
      "metadata": {
        "id": "zyKGoZSPi0Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_clusters = linkage_dendrogram(rescaledDataset, 2)"
      ],
      "metadata": {
        "id": "aDJETbfmEA8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hc, clust_labels = clustering(rescaledDataset, 5)"
      ],
      "metadata": {
        "id": "CQKZi7WhEKwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df = pd.DataFrame(rescaledDataset.index, index = clust_labels, columns = ['Ticker'])"
      ],
      "metadata": {
        "id": "szj5qPIqERT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df = cluster_df.sort_index()"
      ],
      "metadata": {
        "id": "T_xtQlczEkEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df.loc[0]"
      ],
      "metadata": {
        "id": "8uKKgogYGLEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means Clustering"
      ],
      "metadata": {
        "id": "guSa_jwmmAJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_SquaredError(X, max_loop):\n",
        "    distorsions = []\n",
        "    for k in range(2, max_loop):\n",
        "        kmeans = KMeans(n_clusters = k)\n",
        "        kmeans.fit(X)\n",
        "        distorsions.append(kmeans.inertia_)\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    plt.plot(range(2, max_loop), distorsions)\n",
        "    plt.xticks([i for i in range(2, max_loop)], rotation=75)\n",
        "    plt.grid(True)\n",
        "\n",
        "def plot_SilhouetteScore(X, max_loop):\n",
        "    silhouette_score = []\n",
        "    for k in range(2, max_loop):\n",
        "        kmeans = KMeans(n_clusters = k,\n",
        "                        random_state = 10,\n",
        "                        n_init = 10)\n",
        "        kmeans.fit(X)\n",
        "        silhouette_score.append(metrics.silhouette_score(X, kmeans.labels_, random_state=10))\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    plt.plot(range(2, max_loop), silhouette_score)\n",
        "    plt.xticks([i for i in range(2, max_loop)], rotation=75)\n",
        "    plt.grid(True)"
      ],
      "metadata": {
        "id": "mY48dAeyGqSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_SquaredError(rescaledDataset, 3)"
      ],
      "metadata": {
        "id": "ewxusn83mzxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_SilhouetteScore(rescaledDataset, 3)"
      ],
      "metadata": {
        "id": "EMe5R8dcm2yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def K_means(X, nclust):\n",
        "    k_means = cluster.KMeans(n_clusters=nclust)\n",
        "    k_means.fit(X)\n",
        "    target_labels = k_means.predict(X)\n",
        "    return k_means, target_labels\n",
        "\n",
        "def plot_Kmeans_results(X, k_means):\n",
        "    centroids = k_means.cluster_centers_\n",
        "    fig = plt.figure(figsize=(16,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    scatter =(ax.scatter(X.iloc[ : ,0],\n",
        "             X.iloc[ : ,1],\n",
        "             c = k_means.labels_,\n",
        "             cmap = \"rainbow\",\n",
        "             label = X.index))\n",
        "    ax.set_title(\"k-Means results\")\n",
        "    ax.set_xlabel(\"Average Return\")\n",
        "    ax.set_ylabel(\"Volatility\")\n",
        "    plt.colorbar(scatter)\n",
        "    plt.plot(centroids[:,0],\n",
        "         centroids[:,1],\n",
        "         \"sg\",\n",
        "         markersize = 15,\n",
        "         color = \"black\")"
      ],
      "metadata": {
        "id": "gxRHXhc5m9cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_means, target_labels = K_means(rescaledDataset,4)"
      ],
      "metadata": {
        "id": "xk7tVW7OnY5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_Kmeans_results(rescaledDataset, k_means)"
      ],
      "metadata": {
        "id": "GchR4VS6ndR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_series =pd.DataFrame(data = rescaledDataset.index, index = k_means.labels_.flatten(), columns = ['Ticker'])"
      ],
      "metadata": {
        "id": "nCHqoFJunf_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_series = clustered_series.sort_index()"
      ],
      "metadata": {
        "id": "XFkCmS9qvMvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(clustered_series.loc[2])"
      ],
      "metadata": {
        "id": "9791hIZQvPYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ClusterMemberCounts(X, k_means):\n",
        "    # show number of stocks in each cluster\n",
        "    clustered_series =(pd.Series(index = X.index, data = k_means.labels_.flatten()))\n",
        "\n",
        "    # clustered stock with its cluster label\n",
        "    clustered_series_all = pd.Series(index=X.index, data=k_means.labels_.flatten())\n",
        "    clustered_series = clustered_series[clustered_series != -1]\n",
        "\n",
        "    #plot the counts\n",
        "    plt.figure(figsize=(16,8))\n",
        "    counts =clustered_series.value_counts().sort_index()\n",
        "    plt.barh(counts.index,counts)\n",
        "    plt.title(\"Cluster Member Counts\")\n",
        "    plt.xlabel(\"Stocks in Cluster\")\n",
        "    plt.ylabel(\"Cluster Number\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SBIDxxWHvdYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_ClusterMemberCounts(rescaledDataset, k_means)"
      ],
      "metadata": {
        "id": "-F621Po8wF5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Affinity Propagation"
      ],
      "metadata": {
        "id": "BBS7Dd-Aypt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Affinity_Propagation(X):\n",
        "    ap = AffinityPropagation()\n",
        "    ap.fit(X)\n",
        "    clust_labels_AP = ap.predict(X)\n",
        "    return ap,clust_labels_AP\n",
        "\n",
        "def plot_affinity(X, crust_labels_AP):\n",
        "    fig = plt.figure(figsize=(16,10)\n",
        "                )\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    scatter = ax.scatter(X.iloc[:,0],\n",
        "                     X.iloc[:,1],\n",
        "                     c = crust_labels_AP,\n",
        "                     cmap = \"rainbow\")\n",
        "\n",
        "    ax.set_title(\"Affinity\")\n",
        "    ax.set_xlabel(\"Average Return\")\n",
        "    ax.set_ylabel(\"Volatility\")\n",
        "\n",
        "    plt.colorbar(scatter)"
      ],
      "metadata": {
        "id": "CRfVDx3ixQGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap,clust_labels_AP = Affinity_Propagation(rescaledDataset)"
      ],
      "metadata": {
        "id": "VGKLnXUE0Blx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_affinity(rescaledDataset, clust_labels_AP)"
      ],
      "metadata": {
        "id": "CWQXJkfq0HVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stock_in_each_cluster(X,ap):\n",
        "    # show number of stocks in each cluster\n",
        "    clustered_series_ap = pd.Series(index=X.index, data=ap.labels_.flatten())\n",
        "    clustered_df_ap = pd.DataFrame(data=X.index, index=ap.labels_.flatten(), columns = ['Ticker'])\n",
        "    clustered_df_ap = clustered_df_ap.sort_index()\n",
        "    # clustered stock with its cluster label\n",
        "    clustered_series_all_ap = pd.Series(index=X.index, data=ap.labels_.flatten())\n",
        "    clustered_series_ap = clustered_series_ap[clustered_series_ap != -1]\n",
        "\n",
        "    return clustered_series_all_ap, clustered_series_ap, clustered_df_ap"
      ],
      "metadata": {
        "id": "xZfnD44v0OLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cluster_member_count(clustered_series_ap):\n",
        "    plt.figure(figsize=(16,10)\n",
        "          )\n",
        "\n",
        "    plt.barh(range(len(clustered_series_ap.value_counts()\n",
        "             )\n",
        "         ), # cluster labels, y axis\n",
        "    clustered_series_ap.value_counts())\n",
        "\n",
        "    plt.title(\"Cluster Member Counts\")\n",
        "    plt.xlabel(\"Stocks in Cluster\")\n",
        "    plt.ylabel(\"Cluster Number\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uXRYZFD70s52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_series_all_ap, clustered_series_ap,clustered_df_ap = stock_in_each_cluster(rescaledDataset,ap)"
      ],
      "metadata": {
        "id": "8SS8K9x-0xSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_df_ap.loc[0]"
      ],
      "metadata": {
        "id": "gmeQ2Ol402U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cluster_member_count(clustered_series_ap)"
      ],
      "metadata": {
        "id": "XTRml45211vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Different Clustering Algorithm  "
      ],
      "metadata": {
        "id": "ZrIvMkgPQ_BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"km\", metrics.silhouette_score(rescaledDataset, k_means.labels_, metric='euclidean'))\n",
        "\n",
        "print(\"hc\", metrics.silhouette_score(rescaledDataset, hc.fit_predict(rescaledDataset), metric='euclidean'))\n",
        "\n",
        "print(\"ap\", metrics.silhouette_score(rescaledDataset, ap.labels_, metric='euclidean'))"
      ],
      "metadata": {
        "id": "y2qj5Cr_Q2HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7J9jZUURgZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}